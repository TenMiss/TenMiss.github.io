<!DOCTYPE html>
<html lang="zh">
<head>
<meta charset="UTF-8">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1.0,user-scalable=no" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black" />
<meta name="renderer" content="webkit" />
<meta name="screen-orientation" content="portrait" />
<meta name="x5-orientation" content="portrait" />
<title>AIMV Laboratory|Artificial Intelligence and Machine Vision</title>
<link rel="stylesheet" type="text/css" href="css/style.css"/>
</head>
<body>
<div class="top clearfix">
    <a href="index.html" target="_blank" class="logo fl"><img src="img/logo.png"/></a>
    <ul class="navbar clearfix fl">
		<li><a href="index.html">网站首页</a></li>
		<li><a href="supervisor.html">负责人</a></li>
		<li><a href="direction.html">科研方向</a></li>
		<li><a href="publication.html">出版物</a></li>
		<li><a href="resource.html">资源</a></li>
		<li><a href="news.html">新闻中心</a></li>
	</ul>
</div>
<div class="breadcrumb" >
	<div class="w1240 clearfix">
		<div class="div2 fl">
			<span><img src="img/home.png">首页</span><i>&gt;</i>
			<span class="on">科研方向</span>
		</div>
	</div>	
</div>
<div class="fuwupage">
	<div class="w1240">			
        <div class="fuwupage-cont">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>全彩3D打印</h3>
                    </div>
                    <img src="img/3D.png" alt=""  width="600" height="350"/>
                </div>
                <div class="l-cont fr">
                    <h3>全彩3D打印</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>课题介绍</strong></h1>				
                    <p>
                        随着工业“5.0”时代的到来，个性化定制被推上时代浪潮，单色3D打印技术已经难以满足多样化、个性化的用户需求。市面上已投入使用的SLA全彩3D打印机，设备笨重、成本高昂、操作复杂，无法满足越来越多的个人使用者。为此，团队通过设计新型混合喷头、研发耗材混色方案、改进3D打印控制系统，解决了耗材混合不均、色彩覆盖面窄、色彩精确度低等挑战性问题，为国内外FDM全彩3D打印机的设计制造提供了新的技术方案，对全彩3D打印技术的发展具有重要的推进作用。研究成果在文化创意、 医疗卫生、文保修复、遥感测绘等领域有着广阔的发展前景和巨大的发展潜力。
                    </p>		
                    <h1><strong>研究成果</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            蒋宾辰,罗明灵, 周岐鸿等.一种可搭载摄像头的多进一出3D打印混色喷头[P].中国, 202011309141.3, 2020-11-20.
                        </li>
                        <li class="new_honor"> 
                            蒋宾辰,罗明灵,张云轩等.一种带有测试平台的彩色3D打印机[P].中国, 202120369182.5, 2021-02-08.
                        </li>
                        <li class="new_honor">
                            罗明灵,蒋宾辰,刘朕等.一种全彩色3D打印耗材的制备方法[P].中国, 202110583697.X, 2021-05-27.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <div class="fuwupage-cont">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>智能分拣</h3>
                    </div>
                    <img src="img/fenjian.jpg" alt=""  width="600" height="350"/>
                </div>
                <div class="l-cont fr">
                    <h3>智能分拣</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>课题介绍</strong></h1>				
                    <p>
                        随着国内经济的迅速发展，物流行业发生了巨大变化，传统的手动分拣无法满足市场需求，分拣业务正朝着自动分拣的方向发展。现有的智能分拣系统存在准确率低，时耗长，可适性差等缺点，无法满足越来越复杂的实际工业场景。为此，团队通过对智能分拣系统的手眼标定、位姿估计、路径规划等环节进行算法优化，实现了工业Bin-Picking场景中高精度快速的智能分拣，为国内外智能分拣系统的设计提供了新的技术方案。研究成果在物流分拣、汽车装配等领域有着广阔的应用前景。
                    </p>		
                    <h1><strong>研究成果</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Cui X, Yu M, Wu L, et al. A 6D Pose Estimation for Robotic Bin-Picking Using Point-Pair Features with Curvature (Cur-PPF)[J]. Sensors, 2022, 22(5): 1805.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <div class="fuwupage-cont">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>低光照图像增强</h3>
                    </div>
                    <img src="img/low-light.PNG" alt=""  width="600" height="350"/>
                </div>
                <div class="l-cont fr">
                    <h3>低光照图像增强</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>课题介绍</strong></h1>				
                    <p>
                        低光图像一直以来存在可见度低和噪声高的问题，其对应的增强方法是一个不适定问题，这主要因为映射增强输出的结果存在多种可能性。在为人类提供较佳的可视化和为机器视觉应用揭示细节方面，低光图像的处理一直是学术界和工业界重点关注的热点。为此，团队根据理想曝光状态，通过BTF将降噪的低光重构图像和光照分量非线性映射为高质量的增强图像。研究成果有广泛的应用场景，如机器视觉、目标跟踪、行人重识别
                        和 HDR重建等。
                    </p>		
                    <h1><strong>研究成果</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Yi Yang, Wei Cao, Shiqian Wu, Zhengguo Li, Multi-scale Fusion of Two LargeExposure-Ratio Images[J]. IEEE Signal Processing Letters. Vol. 25, no. 12, pp: 
                            1885-1889, 2018. 
                        </li>
                        <li class="new_honor">
                            Wei Cao, Shiqian Wu, Dianwei Wang, Jiaxin Wu, A High Visibility and SNR 
                            image from One Single-Shot Low-Light Image[J]. IEEE Computer Graphics and 
                            Applications. Vol. 41, no. 5, pp: 124-137, 2020.
                        </li>
                        <!-- <li class="new_honor">
                            Wei Cao, Shiqian Wu, Zhaoyi Liu, Dianwei Wang and Sos Agaian, Illumination Estimation via Sparse Bright Channel for Enhancing Under-exposed Images[J]. IEEE Transactions on Cybernetics.
                        </li> -->
                    </ul>
                </div>
            </div>				
        </div>

        <div class="fuwupage-cont">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>3D成像</h3>
                    </div>
                    <img src="img/3DCX.png" alt=""  width="600" height="500"/>
                </div>
                <div class="l-cont fr">
                    <h3>3D成像</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>课题介绍</strong></h1>				
                    <p>
                        在科技快速发展的今天，三维信息逐渐成为人类认识世界和改造世界的手段。作为运用范围广、理论研究较深的三维重建方法，结构光一直是人们研究的热点。结构光系统追求高精度，高效率和低成本，因此团队对结构光系统测量中标定方法、图案编码、相位展开等方面提出了高效且鲁棒的改进算法。针对结构光在特殊环境下的重建问题，团队提出了高反光零件和镜面反射物体的解决方案，
                        对工厂的工业化具有重要的意义。该研究成果在工业检测、消费娱乐方面有着巨大的发展前景和用处。
                    </p>		
                    <h1><strong>研究成果</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Han Hao, Wu Shiqian, Song Zhan. Curved LCD based deflectometry method for specular surface measurement[J]. Optics and Lasers in Engineering. 2022, 151: 106909. 
                        </li>
                        <li class="new_honor">
                            Han Hao, Wu Shiqian, Song Zhan, et al. 3D reconstruction of the specular surface using an iterative stereoscopic deflectometry method[J]. Optics Express, 2021,29(9): 12867-12879.    
                        </li>
                        <li class="new_honor">
                            Deng, G., Wu, S., Zou, L., Cao, W., & Wan, Z. (2022). A gamma self‐correction method via chord distribution coding in fringe projection profilometry. Electronics Letters.
                        </li>
                        <li class="new_honor">
                            Deng, G., Wu, S., Zou, L., Cao, W., & Han, H. (2022). Robust gamma correction based on chord distribution coding considering projector defocusing. Applied Optics, 61(10), 2842-2849.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <div class="fuwupage-cont">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>基于双目视觉的车辆尺寸测量</h3>
                    </div>
                    <img src="img/shijue.png" alt=""  width="600px" height="400px"/>
                </div>
                <div class="l-cont fr">
                    <h3>基于双目视觉的车辆尺寸测量</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>课题介绍</strong></h1>				
                    <p>
                        车辆轮廓尺寸超限判定对交通系统愈发重要。车辆尺寸超限判定是通过对车辆的长、宽、高进行计算，然后与国家规定的各项标准进行参照对比，从而找出是否存在超限现象。传统的尺寸测量方法采用激光雷达技术，不仅成本高昂，而且可视化程度低、不直观。针对该问题，本团队充分利用现有交通摄像头系统，降低成本，利用机器视觉技术测量车辆尺寸：采用高斯混合模型，解决车辆的实时检测与跟踪问题；结合双目视觉技术重建车辆上的稀疏特征点，利用这些特征点的最大范围实现车辆尺寸估计功能；改进稀疏特征点检测，提升系统鲁棒性；评估与提升双目标定、水平面标定等模块的性能，实现高精度的车辆尺寸估计。研究成果已应用于高速公路的货车尺寸实时测量。
                    </p>		
                    <h1><strong>课题支持</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            2022年：基于双目视觉的车辆尺寸测量（南昌众加利公司，45万）
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <div class="fuwupage-cont">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>动态模糊神经网络</h3>
                    </div>
                    <img src="img/DFNN.PNG" alt="" width="600px" height="350px" />
                </div>
                <div class="l-cont fr">
                    <h3>动态模糊神经网络</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>课题介绍</strong></h1>				
                    <p>
                        本研究方向在模糊神经网络理论基础下，用以解决使用者在缺乏模糊理论、神经网络以及应用对象的全面知识的情况下，如何快速、自动地构造一个有效的模糊神经网络的问题。主要研究内容包括：
                        1）动态模糊神经网络的结构。
                        2）结构与参数确定同时进行。
                        3）动态模糊神经网络的学习方法：规则产生准则、分级学习思想、前提参数分配、结果参数确定、修剪技术，以及结构辨识和输入空间的划分。
                        4）动态模糊神经网络不同算法的实现：修剪技术中奇异值分解方法、特征值分解方法、列主元方法和总体最小二乘方法，以及参数调节方法中扩展的卡尔曼滤波方法。
                    </p>		
                    <h1><strong>研究成果</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            近年来，本研究方向先后承担和完成了多项相关的应用项目，出版专著2部，在国内外核心学术刊物上发表50余篇高水平学术论文，被SCI、EI、ISTP收录20余篇，其中文章“动态模糊神经网络：一种新的函数逼近方法”被引用392次。
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <div class="fuwupage-cont">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>模式识别</h3>
                    </div>
                    <img src="img/face.PNG" alt="" width="580px" height="350px" />
                </div>
                <div class="l-cont fr">
                    <h3>模式识别</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>课题介绍</strong></h1>				
                    <p>
                        本研究方向是以模式识别理论为基础，利用人工智能技术、图像增强、深度学习等手段研究满足特殊性能要求的方法。主要研究内容有：
                        1）人脸、性别、年龄等识别：对不同光照条件下成像的人脸图像进行处理，消除光照影响，增强人脸局部纹理信息，在人脸识别应用中提升识别准确率。根据输入的人脸图像判断其性别，改进FLD方法，使得类间距与类内距之比为无穷大，从而得到没有交集的最有效的判别性别特征。根据输入的人脸图像判断其年龄范围。
                        2）字符识别：针对字符的特点，设计研究合理的图像预处理算法，研究字符的归一化和细化处理方法，建立字符标准特征库。
                    </p>		
                    <h1><strong>研究成果</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            近年来，本研究方向先后承担和完成了国家自然科学基金、江西省自然科学基金3项，以及多项相关的应用项目，获得发明专利2项，在国内外核心学术刊物上发表30余篇高水平学术论文，被SCI、EI、ISTP收录20余篇，其中文章“人脸温谱图的血流模型及其在人脸识别上的应用”被微软学术搜索列为机器学习及模式识别领域的顶级文章。  
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <div class="fuwupage-cont">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>高动态范围图像/视频处理</h3>
                    </div>
                    <img src="img/HDR.PNG" alt="" width="580px" height="470px" />
                </div>
                <div class="l-cont fr">
                    <h3>高动态范围图像/视频处理</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>课题介绍</strong></h1>				
                    <p>
                        本研究方向是以图像处理理论为基础，利用图像建模和绘制、图像拼接、图像融合、图像配准等手段研究高动态范围图像/视频的方法。主要研究内容有：
                        1）相机响应函数：图像的辐照度（irradiance）和场景的辐射度（radiance）具有非线性关系，通过估计光照强度和输出图像的像素值之间的关系，即相机响应函数，可以得到高动态图像。
                        2）移动目标检测：实时处理大量视频数据，分析、定位和分割出感兴趣目标，跟踪已检测到的运动目标，通过跟踪分析和识别目标的行为。
                        3）图像配准：将不同时间、不同成像设备或不同条件下获取的多幅图像进行匹配和叠加。
                        4）色调映射：进行大幅度的对比度衰减将场景亮度变换到可以显示的范围，同时保持图像细节与颜色，使得获得的高动态图像能在显示器中正常显示。
                        5）图像合成：将获得的高动态背景图像与高动态目标图像合成出最能满足要求的结果图像。

                    </p>		
                    <h1><strong>研究成果</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            近年来，本研究方向先后承担了国家自然科学基金1项，相关的应用项目多项，获得发明专利多项，包括2项美国专利和2项新加坡专利；在国内外核心学术刊物上发表20余篇高水平学术论文，被SCI、EI、ISTP收录10余篇；已开发手机平台及计算机平台2款产品，且部分成果展示在ACM Siggraph 及 ACM Siggraph Asia上。

                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <div class="fuwupage-cont">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>机器人技术</h3>
                    </div>
                    <img src="img/robot.png" alt="" width="600px" height="300px" />
                </div>
                <div class="l-cont fr">
                    <h3>机器人技术</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>课题介绍</strong></h1>				
                    <p>
                        本研究方向是以人工智能机器人技术为理论基础，结合肢体运动、视觉系统等多种手段研究满足特殊性能要求的方法。主要进行
                        步态动态特性分析，建立四足疾驰步态下的混杂动态模型。系统动力学模型沿周期轨道投影到与周期轨道正交的截面上，
                        将非线性的奔跑步态模型转化为具有周期特性的时变线性系统模型。根据四足机器人周期被动步态的运动轨迹，利用多项式拟合的方法将轨迹作为虚拟约束施加到实际四足机器人上，实现相应步态。
                    </p>		
                    <h1><strong>研究成果</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Q. Y. Liu, X. D. Chen, B. Han, X. Lou, “Virtual Constraint Based Control of Bounding Gait of Quadruped Robots,” Journal of Bionic Engineering, 2017, 14(2):218–231.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

    </div>
</div>

<div class="footer">
	<div class="w1240">
		<div class="div1 clearfix">
			<ul class="clearfix fr">
				<li><a href="index.html">网站首页</a></li>
				<li><a href="supervisor.html">负责人</a></li>
				<li><a href="direction.html">科研方向</a></li>
				<li><a href="publication.html">出版物</a></li>
				<li><a href="resource.html">资源</a></li>
				<li><a href="news.html">新闻中心</a></li>
			</ul>
		</div>
		<div class="div2 clearfix">
			<div class="left fl">
				<p class="p1">
					地址：武汉市青山区，武汉科技大学信息科学与工程学院，430081<br />
					Copyright©2022 人工智能与机器视觉实验室 版权所有<br />
					备案号：皖ICP备xxxxxxxx号-1
				</p>
			</div>
			<div class="right fr">
				<p class="p3">联系方式</p>   
				<p class="p4"><a href="mailto:shiqian.wu@wust.edu.cn">shiqian.wu@wust.edu.cn</a></p>
			</div>					
		</div>
	</div>
</div>		


<script src="js/jquery.js"></script>
<script src="js/SuperSlide.js"></script>
<script src="js/plugin.js"></script>
<script src="js/banner.js"></script>
<script src="js/index.js"></script>
<script src="js/more.js"></script>
</body>
</html>
